{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedrovelozo/TCC-Pedro-Velozo-ENG1132/results/../model_runner.py:307: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if model_name is \"Bicubic\":\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from model_runner import ModelRunner\n",
    "from image_helper import ImageHelper\n",
    "from SRCNN_different_specs import SRCNN\n",
    "from SRCNN import SRCNN\n",
    "from custom_image_dataset import CustomImageDataset\n",
    "\n",
    "sys.path.append('../DBPN/')\n",
    "from DBPN_copied import DBPN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT=\"../datasets/\"\n",
    "DATASET_NAME = \"set14\"\n",
    "# DATASET_NAME = \"Set5\"\n",
    "FULL_DATASET_PATH = f\"{DATASET_ROOT}{DATASET_NAME}\"\n",
    "model_runner = ModelRunner()\n",
    "image_helper = ImageHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load models\n",
    "srcnn = SRCNN(f2=5).to(device)\n",
    "dbpn = more_epochs_less_data_model = DBPN(num_channels=3, base_filter=64,  feat = 256, num_stages=7, scale_factor=4).to(device)\n",
    "\n",
    "try:\n",
    "    srcnn.load_state_dict(torch.load('./srcnn/trained_models/model_f2_5.pth'))\n",
    "    dbpn.load_state_dict(torch.load('./dbpn/trained_models/model-05-08-epoch=0-299.pth'))\n",
    "\n",
    "except:\n",
    "    srcnn.load_state_dict(torch.load('./srcnn/trained_models/model_f2_5.pth', map_location=torch.device('cpu')))\n",
    "    dbpn.load_state_dict(torch.load('./dbpn/trained_models/model-05-08-epoch=0-299.pth', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/pedrovelozo/TCC-Pedro-Velozo-ENG1132/env/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/pedrovelozo/TCC-Pedro-Velozo-ENG1132/env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "14it [00:00, 58.96it/s]\n",
      "14it [00:00, 25.58it/s]\n",
      "14it [00:00, 73.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRCNN</th>\n",
       "      <td>24.815783</td>\n",
       "      <td>0.726430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBPN</th>\n",
       "      <td>23.480452</td>\n",
       "      <td>0.660932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bicubic</th>\n",
       "      <td>22.933111</td>\n",
       "      <td>0.659410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PSNR      SSIM\n",
       "SRCNN    24.815783  0.726430\n",
       "DBPN     23.480452  0.660932\n",
       "Bicubic  22.933111  0.659410"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_runner.compare_models([\n",
    "                              {\"name\": \"SRCNN\", \"model\": srcnn, \"scale\": 3},\n",
    "                              {\"name\": \"DBPN\", \"model\": dbpn,\n",
    "                               \"input_transform\":lambda input: transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Resize(\n",
    "                                    (input.size[1] // 4, input.size[0] // 4), interpolation=Image.BICUBIC),\n",
    "                                ])(input),\n",
    "                                \"should_only_downsampple\": True, \"scale\":4, \"unsqueeze\": True },\n",
    "                              ], FULL_DATASET_PATH, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(656)\n",
    "print(656 // 4)\n",
    "print((656 // 4)*4)\n",
    "\n",
    "print()\n",
    "\n",
    "print(529)\n",
    "print(529 // 4)\n",
    "print((529 // 4)*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([3, 128, 192])\n",
    "dbpn(a.unsqueeze(0).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn([1, 3, 128, 192])\n",
    "dbpn(b.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXAMPLE = \"../datasets/set14/ppt3.png\"\n",
    "\n",
    "image_helper.show_tensor_as_images_side_by_side(\n",
    "    [\n",
    "        {\n",
    "            \"label\": \"Low Res\",\n",
    "            \"tensor\": image_helper.downsample_image_as_tensor(\n",
    "                IMAGE_EXAMPLE, 4, interpolation=Image.BICUBIC,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"DBPN\",\n",
    "            \"tensor\": image_helper.apply_model_to_image(\n",
    "                model=dbpn,\n",
    "                image=IMAGE_EXAMPLE,\n",
    "                downsample_factor=4,\n",
    "                should_upsample=False,\n",
    "                unsqueeze=True\n",
    "            )\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../datasets/set14/ppt3.png')\n",
    "\n",
    "a = image_helper.downsample_image_as_tensor(image, 4, interpolation=Image.BICUBIC, unsqueeze=True)\n",
    "print(image.size)\n",
    "print(a.shape)\n",
    "b = dbpn(a.to(device))\n",
    "print(b.shape)\n",
    "\n",
    "# a = image_helper.crop_image_to_nearest_even_dimensions_and_transform_to_tensor(image)\n",
    "\n",
    "# print(image.size)\n",
    "# print(a.shape)\n",
    "# image_center_crop = transforms.CenterCrop((image.size[1], image.size[0]-1))(image)\n",
    "# image_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "# print(image_center_crop.size)\n",
    "# image_center_crop\n",
    "# print(image_tensor.shape)\n",
    "\n",
    "# a = dbpn(image_tensor.unsqueeze(0).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "592 // 4 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
